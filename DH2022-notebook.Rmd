---
title: "DH 2022 Notebook"
output: html_notebook
---

This notebook documents my process in modeling selected early twentieth century immigrant autobiographies using Syuzhet.

## Get First Text

- Set working directory
```{r}
setwd("/Users/rodrigue8/Documents/research/conferences/2022-DH")
```

- load Syuzhet

```{r}
library(syuzhet)
```


- Load Antin text.

```{r}
antin_text <- get_text_as_string("corpus/Antin22.txt")
```

- Use Syuzhet's sentence parser to create a sentence vector. Length: 5695.

```{r}
antin_sentences <- get_sentences(antin_text)
```

- Examine vector to determine further cleaning of front/back material. Back material includes glossary beginning at line 5422.
- Create new sentence vector without glossary.

```{r}
antin_no_gloss_sentences <- antin_sentences[1:5421]
```


I ran default syuzhet lexicon first to try it out. I created a data frame to quicly compare sentence text and score.

```{r}
antin_no_gloss_sentence_scores_sy <- get_sentiment(antin_no_gloss_sentences, method="syuzhet")
antin_compare_sy_sent <- cbind(antin_no_gloss_sentences, antin_no_gloss_sentence_scores_sy)
```


## Initial valdiation
Run all four Syuzhet lexicons.

```{r}
library(syuzhet)
antin_no_gloss_sentence_scores_sy <- get_sentiment(antin_no_gloss_sentences, method="syuzhet")
antin_no_gloss_sentence_scores_afinn <- get_sentiment(antin_no_gloss_sentences, method="afinn")
antin_no_gloss_sentence_scores_bing <- get_sentiment(antin_no_gloss_sentences, method="bing")
antin_no_gloss_sentence_scores_nrc <- get_sentiment(antin_no_gloss_sentences, method="nrc", lang="english")
```

I paused here to plot all four, unscaled. Basic shapes in agreement. 

I then used simple_plot to compare different smoothing methods for Syuzhet lexicon scores.

```{r}
simple_plot(antin_no_gloss_sentence_scores_sy)
```

I then proceeded to do the same using VADER. This produced a warning message, but it did not appear to affect results. I got the expected number of "observations" ie sentence scores.

```{r}
library(vader)
antin_vader_sentence_scores <- vader_df(antin_no_gloss_sentences)
```

After a bunch of fails, I realized that in order to visualize just the sentence scores, I would need to extract the "compound" column as a vector.

```{r}
antin_vader_vec <-antin_vader_sentence_scores$compound
plot(antin_vader_vec, type="l", main="Antin Sentiment Using Vader", xlab="Narrative Time", ylab="Emotional Valence", col="red")
simple_plot(antin_vader_vec)
```

## Modeling a second text

### Bok

I thought I was going to do Steiner next, but the process of cleaning up the OCR made me hesitant. Then I remembered that there were other texts in Gutenberg. So I'm going to start with those.

Load Bok

```{r}
bok_text <- get_text_as_string("corpus/bok22.txt")
```

Parse into sentences, get syuzhet scores, simple plot.

```{r}
bok_sentences <- get_sentences(bok_text)
bok_sentence_scores_sy <- get_sentiment(bok_sentences, method="syuzhet")
bok_compare_sy_sent <- cbind(bok_sentences, bok_sentence_scores_sy)
simple_plot(bok_sentence_scores_sy)
```

Let's speed this up and do the rest in single chunks.

### Riis
```{r}
riis_text <- get_text_as_string("corpus/riis22.txt")
riis_sentences <- get_sentences(riis_text)
riis_sentence_scores_sy <- get_sentiment(riis_sentences, method="syuzhet")
riis_compare_sy_sent <- cbind(riis_sentences, riis_sentence_scores_sy)
simple_plot(riis_sentence_scores_sy)
```
### Pupin

```{r}
pupin_text <- get_text_as_string("corpus/pupin22.txt")
pupin_sentences <- get_sentences(pupin_text)
pupin_sentence_scores_sy <- get_sentiment(pupin_sentences, method="syuzhet")
pupin_compare_sy_sent <- cbind(pupin_sentences, pupin_sentence_scores_sy)
simple_plot(pupin_sentence_scores_sy)
```

